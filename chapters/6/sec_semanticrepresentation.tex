\section{Detection of Semantic Representation}
\label{sec:discussion:detectionofsemanticrepresentation}
We were able to achieve a \tvt accuracy of 79.54\% in the Semantic 
Representation Experiment, which provides evidence that there is a strong 
correlation between the EEG data of participants and the word vectors mapped to 
each symbol. This confirms our hypothesis that we would see statistically 
significant accuracy on the \tvt test. Previous work has mostly focused on MEG 
and fMRI~\cite{Mitchell2008,Sudre2012}, but our results show that a similar 
word decoding methodology can also be applied to EEG data even when the 
paradigm differs. 

Murphy et al. also showed this methodology has promise in 
EEG~\cite{Murphy2009}, but was focused on two semantic categories of concrete 
nouns (tools and mammals) while we expand to a much more varied vocabulary and 
utilize a different paradigm based on reinforcement learning. Though EEG has 
its limitations, it is sometimes preferable due to reduced cost and improved 
portability over MEG and fMRI. This makes the adaption of this methodology to 
EEG an important contribution and goal for research in this area, as it lowers 
the costs for semantic representation research by several orders of magnitude.  
Additionally, there are individual benefits compared to each modality such as 
the increased time resolution of EEG compared to fMRI or increased sensitivity 
to more brain areas compared to MEG.

It is also notable that our stimuli were symbols rather than wordforms. 
Previous studies used written words alongside 
illustrations~\cite{Mitchell2008,Sudre2012}, and recent work showed that 
accuracy is higher when utilizing illustrations for word 
context~\cite{pereira2018toward}. Critiques of earlier work posited that the 
models were simply leveraging the brain's visual representations, such as the 
dominant shapes in the image or the length of the word, and might not be 
related to word meaning. Because the mapping of symbols to words was totally 
arbitrary, our results are strong evidence that models leveraging word vectors 
truly model the brain's representation of word \emph{meaning}, and not some 
low-level visual features of the stimuli.

In previous work, participants were requested to visualize the concepts while 
viewing words and images~\cite{Mitchell2008,Sudre2012}. In our experiment, 
participants were provided no instructions regarding visualization, only 
instructed to perform the reinforcement learning task. This provides evidence 
that the semantic representations are detectable in a more complicated word 
mapping task and not only when performing the simple visualization tasks. This 
also shows that participants do not need to be coached to explicitly visualize 
the concepts in order to detect semantics.

We also achieved high accuracy on the \tvt test using a more direct and simple 
averaging mechanism. While some previous literature has approached this by 
grouping and averaging only the exposures of a single participant (giving an 
averaged result for each participant-word pair)~\cite{Mitchell2008,Sudre2012}, 
we found that the models performed best when we averaged the sensor readings 
across all participants, with no extra accounting for the differing shape or 
size of participants' heads. The smoothness of EEG likely contributes to the 
success of this approach.

Our work also shows that the word vector approach generalizes to different 
parts of speech. Many previous studies used only concrete 
nouns~\cite{Mitchell2008,Sudre2012,Murphy2009}. Although the majority of our 
words were nouns, participants saw concrete nouns, abstract nouns, pronouns, 
adjectives, and verbs. Even concrete and abstract nouns, while both the same 
part of speech, can have different electrophysiological attributes which make 
semantic modelling a more complicated task~\cite{barber2013concreteness}. This 
aligns with a recent study by Pereira et al.  hich had a similar distribution 
of parts of speech for an fMRI model but utilized much more training 
data~\cite{pereira2018toward}. To score high on the \tvt test the model must be 
able to discriminate effectively between these categories to some degree. Thus, 
our methodology can detect a semantic difference between words both within and 
between various parts of speech.

While this methodology has been applied to other brain imaging modalities 
before, and we are not the first to show evidence of semantic represnetation 
using EEG, this initial experiment contributes to the body of evidence 
supporting the use of EEG for semantic represenation research and provides 
iteration and new insight on the technique of using linear models to predict 
word vectors as a function of brain data.
