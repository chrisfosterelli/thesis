\startchapter{Related Work}
\label{chapter:relatedwork}

\section{Early Semantic Research}

In very early work, semantics in the brain have been analyzed through the 
traditional detection of ERPs in EEG 
data~\cite{kutas1980reading,kuperberg2007neural}. When participants read a 
sentence that involves a semantically inappropriate statement (e.g., he spread 
the warm bread with socks), the brain elicits a measurement ERP response known 
as the N400. This negative component peaks approximately 400 milliseconds after 
stimulus onset, hence the name N400.

While visual inspection of evoked EEG data can be useful for measuring 
phenomenon that are directly visible in the data, such as with ERPs, more 
complex patterns can be detected with automated analysis methods such as 
machine learning techniques. This can be useful for identifying attributes of 
the EEG data that is not tied to simple magnitude comparisons, or when analysis 
needs to be performed on an online setting (i.e, in real time). Additionally, 
grand average ERPs can be different in timing and amplitude between 
participants depending on age variations~\cite{cunningham2000speech}. For 
example, an early application of machine learning classification on brain data 
was the use by Wang et al. to detect whether or not participants were viewing a 
picture of reading sentences based on their fMRI activity~\cite{Wang2002}. 

Machine learning methods can also be useful for detecting semantic information.  
Mitchell et al. were able to categorize trials of participants reading a word 
into one of twelve semantic categories based on the word in an early 
paper~\cite{Mitchell2002}. Similarly to the research based on ERPs, they could 
also detect when a participant found a sentence to be semantically ambigious. 
Shinkareva et al. was able to identify individual concepts and their 
corresponding semantic categories for a participant based only on the training 
data from other participants~\cite{Shinkareva2008}. This indicated the 
existence of stable semantic representations of concepts in the brain that are 
shared across people. While much of this previous work was done in fMRI, there 
was similar work using EEG that provided evidence of the ability to identify 
limited semantics. For example, Gu et al. was able to perform sentiment 
analysis (a more simple type of semantic analysis that categorizes concepts 
into positive, negative, or neutral categories) of a limited set of sentences 
using EEG data~\cite{Gu2014}. However, work in this area utilizing EEG did not 
quite match the level of semantic detail that was found in studies using fMRI.

\section{Generalizable Semantic Models}

Until 2008, most research utilized models that required many repeated training 
examples of a stimulus before it could correctly identify that stimulus in the 
future~\cite{kutas1980reading,kuperberg2007neural,Wang2002,Mitchell2002,Shinkareva2008,Gu2014}.
In effect, this means that these models are only capable of recognizing brain 
states that the machine learning algorithm had already been trained to 
recognize. As neuroscience training data is very expensive to collect compared 
to other applications of machine learning, this could be viewed as a limitation 
of the semantic models. It would be impractical to collect sufficient trials of 
every possible word in the English language for each subject.

By training a machine learning model to accurately predict the expected fMRI 
activity of a participant reading concrete nouns, Mitchell et al. showed that 
the semantic features of a word are correlated with fMRI data of a participant 
viewing the word~\cite{Mitchell2008}. Although the model is trained using 
observed fMRI data of participants reading 60 concrete nouns, the model is 
capable of generating predictions for thousands of words for which it has never 
seen fMRI data. This is achieved by encoding each word as a vector of 
intermediate features based on the co-occurrences of the word with 25 verbs in 
a large text corpus. Rather than training the model to recall a given word 
categorization, this forces the weights to model the semantic patterns in the 
brain. Mitchell et al. demonstrated a direct relationship between the 
statistics of word co-occurrence and the neural activation associated with each 
word's meaning~\cite{Mitchell2008}.

Another key study in this area reproduced Mitchell et al.~\cite{Mitchell2008} 
using MEG~\cite{Sudre2012}. Sudre et al. used MEG data and word vectors to 
correctly identify concrete nouns. However, in this work, the  word vectors 
were based on human responses to semantic questions about the word (e.g. Is it 
alive?  It it bigger than a golf ball?) rather than automatically generated 
features from text corpora. The use of MEG allowed Sudre et al. to pinpoint in 
time when the semantics of a word could be detected and when the strength of 
the representation was the strongest. Subsequent work showed that, with some 
fine tuning, word vectors derived from a text corpus could be as accurate for 
predicting the word a person is reading as the behavioral vectors used in Sudre 
et al.~\cite{Murphy2012}.

\section{Larger Language Structures}

While most of the work discussed here focuses on the analysis of single 
concrete nouns, recent work has been done that extends into more complicated 
language structures such as phrases or sentences. Chang et al. showed that it 
is possible to identify adjective-noun phrases with classification models 
utilizing fMRI data, and that vector-based semantic models are related to brain 
activity of participants reading the adjective-noun phrases~\cite{Change2009}.

\section{Research in EEG}

EEG data, however, has remained comparatively underutilized for the 
fine-grained distinction of individual words. This may be due to the challenges 
that come with EEG data (e.g. lower spatial resolution, comparatively poor 
signal-to-noise ratio).  One of the first studies to successfully use word 
vectors to differentiate words EEG was performed by Murphy et al in 
2009~\cite{Murphy2009}.  In addition, they were able to distinguish between two 
semantic classes (land mammals or work tools)~\cite{Murphy2009,Murphy2011}. The 
accuracy was as high as 98\% when averaged over multiple analyses, providing 
evidence that EEG could give more cost effective exploration of brain-based 
semantics in more naturalistic environments.  Our study adds to the body of 
evidence that EEG can be used to model semantics representations with 
significant accuracy.

\section{Learning-related Literature}

In addition to studying representation, in this work we also examine learning. 
Our novel experimental design also allows us to study participant learning in a 
unique fashion by applying a machine learning model of semantic 
representations. Learning has been traditionally studied in EEG using ERPs. The 
ERP of particular interest for learning is known as the \emph{reward 
positivity}~\cite{proudfit2015reward}. The amplitude of the reward positivity 
is associated with behavior-measured learning when presented in a reinforcement 
learning paradigm~\cite{holroyd2002neural, sutton1998reinforcement, 
williams2017application}. However, the exact nature of the reward positivity's 
association with learning remains unclear. In some work the reward positivity 
is found to have a progressively reduced amplitude as participants perform 
better on the task, and in other work this correlation has not been 
consistently detected~\cite{walsh2012learning}. We aim to provide an 
alternative tool for analyzing learning in this paradigm, which may provide 
insight into the reward positivity and offer other benefits.

\section{Conclusion}

This paper expands on previous work by adapting the existing semantic analysis 
methodology~\cite{Mitchell2008,Sudre2012} to EEG data.  We use a novel 
experimental design, in which participants perform a reinforcement learning 
task that guides participants through learning an artificial language. To 
detect semantics we trained a machine learning model to map from raw EEG signal 
to word vectors derived from an artificial neural network. We evaluate this 
model using the 2 vs 2 test, a method originally developed by Mitchell et 
al.~\cite{Mitchell2008}, that simplifies a complex multiple regression model 
into a binary classification task. Our results show that 
\begin{inparaenum}[(1)]
  \item we can detect the reward positivity in this learning paradigm
  \item the reward positivity diminishes after the first correct trial
  \item the semantic representation of words is detectable in EEG, and \item we 
  can detect learning as participants progress in through the paradigm,
\end{inparaenum}
closely tracking an ERP analysis.

