\startchapter{Related Work}
\label{chapter:relatedwork}

\section{Early Semantic Research}

In very early work, semantics in the brain have been analyzed through the 
traditional detection of ERPs in EEG 
data~\cite{kutas1980reading,kuperberg2007neural}. When participants read a 
sentence that involves a semantically inappropriate statement (e.g., he spread 
the warm bread with socks), the brain elicits a measurement ERP response known 
as the N400. This negative component peaks approximately 400 milliseconds after 
stimulus onset, hence the name N400.

While visual inspection of evoked EEG data can be useful for measuring 
phenomenon that are directly visible in the data, such as with ERPs, more 
complex patterns can be detected with automated analysis methods such as 
machine learning techniques. This can be useful for identifying attributes of 
the EEG data that is not tied to simple magnitude comparisons, or when analysis 
needs to be performed on an online setting (i.e, in real time). Additionally, 
grand average ERPs can be different in timing and amplitude between 
participants depending on age variations~\cite{cunningham2000speech}. For 
example, an early application of machine learning classification on brain data 
was the use by Wang et al. to detect whether or not participants were viewing a 
picture of reading sentences based on their fMRI activity~\cite{Wang2002}. 

Machine learning methods can also be useful for detecting semantic information.  
Mitchell et al. were able to categorize trials of participants reading a word 
into one of twelve semantic categories based on the word in an early 
paper~\cite{Mitchell2002}. Similarly to the research based on ERPs, they could 
also detect when a participant found a sentence to be semantically ambigious. 
Shinkareva et al. was able to identify individual concepts and their 
corresponding semantic categories for a participant based only on the training 
data from other participants~\cite{Shinkareva2008}. This indicated the 
existence of stable semantic representations of concepts in the brain that are 
shared across people. While much of this previous work was done in fMRI, there 
was similar work using EEG that provided evidence of the ability to identify 
limited semantics. For example, Gu et al. was able to perform sentiment 
analysis (a more simple type of semantic analysis that categorizes concepts 
into positive, negative, or neutral categories) of a limited set of sentences 
using EEG data~\cite{Gu2014}. However, work in this area utilizing EEG did not 
quite match the level of semantic detail that was found in studies using fMRI.

\section{Generalizable Semantic Models}

Until 2008, most research utilized models that required many repeated training 
examples of a stimulus before it could correctly identify that stimulus in the 
future~\cite{kutas1980reading,kuperberg2007neural,Wang2002,Mitchell2002,Shinkareva2008,Gu2014}.
In effect, this means that these models are only capable of recognizing brain 
states that the machine learning algorithm had already been trained to 
recognize. As neuroscience training data is very expensive to collect compared 
to other applications of machine learning, this could be viewed as a limitation 
of the semantic models. It would be impractical to collect sufficient trials of 
every possible word in the English language for each subject.

By training a machine learning model to accurately predict the expected fMRI 
activity of a participant reading concrete nouns, Mitchell et al. showed that 
the semantic features of a word are correlated with fMRI data of a participant 
viewing the word~\cite{Mitchell2008}. Although the model is trained using 
observed fMRI data of participants reading 60 concrete nouns, the model is 
capable of generating predictions for thousands of words for which it has never 
seen fMRI data. This is achieved by encoding each word as a vector of 
intermediate features based on the co-occurrences of the word with 25 verbs in 
a large text corpus. Rather than training the model to recall a given word 
categorization, this forces the weights to model the semantic patterns in the 
brain. Mitchell et al. demonstrated a direct relationship between the 
statistics of word co-occurrence and the neural activation associated with each 
word's meaning~\cite{Mitchell2008}.

Another key study in this area reproduced Mitchell et al.~\cite{Mitchell2008} 
using MEG~\cite{Sudre2012}. Sudre et al. used MEG data and word vectors to 
correctly identify concrete nouns. However, in this work, the  word vectors 
were based on human responses to semantic questions about the word (e.g. Is it 
alive?  It it bigger than a golf ball?) rather than automatically generated 
features from text corpora. The use of MEG allowed Sudre et al. to pinpoint in 
time when the semantics of a word could be detected and when the strength of 
the representation was the strongest. Subsequent work showed that, with some 
fine tuning, word vectors derived from a text corpus could be as accurate for 
predicting the word a person is reading as the behavioral vectors used in Sudre 
et al.~\cite{Murphy2012}.

\section{Larger Language Structures}

While most of the work discussed here focuses on the analysis of single 
concrete nouns, recent work has been done that extends into more complicated 
language structures such as phrases or sentences. 

Chang et al. showed that it is possible to identify adjective-noun phrases with 
classification models utilizing fMRI data, and that vector-based semantic 
models are related to brain activity of participants reading the adjective-noun 
phrases~\cite{Change2009}. Fyshe showed that a similar computational model 
based on word vectors could also be applied to adjective noun 
phrases~\cite{afyshethesis}.

Pereira et al. adapted the semantic representation model for whole 
sentences~\cite{pereira2018toward}, and covered a much larger semantic variety 
of words than previous work. In our work, we will focus on adapting the single 
word paradigm to EEG. However, with this ground work established in EEG more 
complicated language structures become an obvious area for future 
experimentation.

\section{Research in EEG}

Compared to fMRI and MEG, EEG data has remained comparatively underutilized for 
the fine-grained distinction of individual words. This may be due to the 
challenges that come with EEG data (e.g. lower spatial resolution, 
comparatively poor signal-to-noise ratio).  One of the first studies to 
successfully use word vectors to differentiate words EEG was performed by 
Murphy et al in 2009~\cite{Murphy2009}. In addition, they were able to 
distinguish between two semantic classes (land mammals or work 
tools)~\cite{Murphy2009,Murphy2011}. The accuracy was as high as 98\% when 
averaged over multiple analyses, providing evidence that EEG could give more 
cost effective exploration of brain-based semantics in more naturalistic 
environments.  Our study adds to the body of evidence that EEG can be used to 
model semantics representations with significant accuracy.

\section{Learning-related Literature}

In addition to studying representation, in this work we also examine learning. 
Our novel experimental design also allows us to study participant learning in a 
unique fashion by applying a machine learning model of semantic 
representations. Learning has been traditionally studied in EEG using ERPs. The 
ERP of particular interest for learning is known as the \emph{reward 
positivity}~\cite{proudfit2015reward}. The amplitude of the reward positivity 
is associated with behavior-measured learning when presented in a reinforcement 
learning paradigm~\cite{holroyd2002neural, sutton1998reinforcement, 
williams2017application}. However, the exact nature of the reward positivity's 
association with learning remains unclear. In some work the reward positivity 
is found to have a progressively reduced amplitude as participants perform 
better on the task, and in other work this correlation has not been 
consistently detected~\cite{walsh2012learning}. We aim to provide an 
alternative tool for analyzing learning in this paradigm, which may provide 
insight into the reward positivity and offer other benefits.

\section{Conclusion}

Traditional analysis methods for semantic information in the brain consist 
mostly of ERP-based techniques, however machine learning methods have been able 
to provide additional insight over magnitude based visual comparisons. Mitchell 
et al. built on these early methods to create an approach that utilizes 
semantic word vectors generated from a text corpus~\cite{Mitchell2008}. This 
approach models the actual semantics of words rather than learning a mapping 
between the brain data and a category, and introduces the ability to generalize 
to words the model has never been trained on before. 

This work, original in fMRI, was further iterated on when adapted to 
MEG~\cite{Sudre2012}. It has also been expanded to include more complex 
language structures such as sentences and adjective-noun 
phrases~\cite{pereira2018toward, afyshethesis}. Our work builds on these to 
adapt the corpus-based approach from Mitchell et al. and the iterations from 
Sudre et al.  to the EEG collection methodology and our reinforcement learning 
based experiment paradigm. The following chapter will describe the experiment 
paradigm, preprocessing techniques, and model framework we use in our 
experiments.
