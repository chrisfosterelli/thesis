\section{Data Collection}

We collected data for 30 participants, via an EEG monitor equipped with 64 
sensors (ActiCHamp, Revision 2, Brainproducts GmbH, Munich, Germany). Five 
participants were excluded: two participants due to technical issues with 
behavioral data collection, two participants due to technical issues with EEG 
collection, and one participant who did not follow task instructions. The 25 
remaining participants consisted of 9 males and 16 females with an average age 
of 20 years and average self-evaluated English fluency of 9.7 out of 10.  The 
majority (21 of 25) were right handed. Of the 64 sensors, two mastoid sensors 
were dedicated as reference electrodes and another electrode was used as the 
ground, leaving 61 total signal electrodes.  Collection was performed in a 
sound-dampened room with participants facing a 19" LCD screen and interacting 
with the experiment using a button controller (VPixx, Vision Science Solutions, 
Quebec, Canada).  The task was written in MATLAB (Version 8.6, Mathworks, 
Natick, U.S.A.) using the Psychophysics Toolbox 
extension~\cite{brainard1997psychophysics}.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{figures/experiment}
  \caption[Experiment Paradigm]{
    The experimental paradigm. Participants were required to learn a mapping of 
    symbols to English words through trial and error. This simulates vocabulary 
    learning.
  }
  \label{fig:experiment}
\end{figure}

Participants viewed a series of symbols from the Tamil and Manipuri alphabets, 
which were assigned to a random English word. The randomization was consistent 
across all participants, but had no relationship to the meaning of the Tamil or 
Manipuri words. While other artificial mappings may have been utilized instead, 
these symbols were not likely to be familiar to candidate participants, were 
readily available existing components from a real language, and ensured roughly 
equal difficulty of translation (for other languages the translation of a word 
may be more obvious to an English speaker than for other words). Utilizing 
symbols also has interesting implications when comparing our results with prior 
work, in which participants viewing visual images and English words could be 
criticized as a detection of visual features rather than of semantics (see 
Section~\ref{sec:discussion:semanticrepresentation} for more details).

There were a total of 60 words and symbols, 43 of which have a definitive part 
of speech category. These consist of 3 pronouns, 3 verbs, 14 adjectives, and 23 
abstract or concrete nouns. The remaining 17 may take the role of multiple 
parts of speech, for example \emph{north} may act as either an abstract noun, 
adverb, or adjective and \emph{run} may be either an abstract noun or a verb. A 
complete list of symbols and words is available in 
Appendix~\ref{chapter:appendix}.

Participants were presented with a symbol, and asked to select the correct word 
from four options. The participant received visual feedback about their 
response: correct (``\CheckmarkBold'') or incorrect (``X''). Figure 
\ref{fig:experiment} illustrates a single trial of the paradigm. This simulates 
learning a language through trial and error. We hypothesized that as 
participants learned the mapping of symbols--to--words, they would also assign 
semantic meaning to each symbol. Our task used a 1--to--1 mapping of 
symbols--to--words over a very small subset of English. Of course, this is not 
representative of learning a complete language but allowed us to detect the 
process of learning the symbol--to--word mapping, mirroring vocabulary 
learning.

To facilitate learning, symbols were selected from a set that grew as the 
experiment progressed. During the first block, participants were presented with 
six symbols (representing three pronouns, three verbs). In subsequent blocks, 
three new symbols (and thus three new words) were added. These three new 
symbols were randomly paired with three previously seen symbols so that each 
block cycled through six symbols. There were a total of 19 blocks, and 60 total 
symbols learned. Throughout the experiment, each of the participants viewed a 
random number of trials (ranging from 0--20, denoted as $n_t$) for each of the 
60 symbols. After the first block, the order in which symbols were added was 
randomly determined, so that no two participants viewed the noun symbols in the 
same order.
  
The stimuli were displayed on a gray background.  Each trial begins with a 
black fixation cross for 700 to 1000 ms, followed by a symbol written in black, 
4.5 cm\textsuperscript{2} in size. The symbol presented was randomly selected 
from the list of six for the block. After 500 ms, four black English words 
appeared in the arrangement of a fixation cross (top, bottom, right, left) 
below the symbol. One of the choices was the correct answer, and the three 
distractor words (incorrect answers) were randomly chosen from the remaining 
five words. The assignment of words to the four locations was randomly 
determined. Participants were instructed to respond by pressing one of the 
buttons on the RESPONSEPixx controller, which also has response buttons 
arranged in a cross. Once a participant made a selection, the selected word 
turned white for 500 ms, the screen changed to a fixation for 700 to 1000 ms, 
and a feedback stimulus appeared for one second (``\CheckmarkBold'' or ``X'').  
If a selection was not made within two seconds, an exclamation mark would 
appear to signify that they took too long to respond. Within a block, ten 
symbols were presented sequentially one at a time and then evaluated for 
accuracy. Participants stayed on the current block until receiving 90\% or 
higher accuracy over the set of ten.
  
To further facilitate the transfer of meaning to symbols, participants also 
viewed three word sentences containing one pronoun, one verb, and one noun 
(e.g., \emph{I am happy}). The sentence phases displayed three sentences before 
and after each word learning phase described above. In these phases, 
participants saw one word at a time for one second each, separated by a 
fixation cross for 700 to 1000 ms, which was followed by four multiple choice 
answers as to indicate what the sentence had said. For the purposes of this 
thesis, the sentence trials were discarded. The participants each saw on 
average 667 ($\sigma = 79$) word exposures, including sentences, with breaks 
provided.  The average task accuracy of individual participants ranges from 
72\% - 90\% and the mean over all participants is 81\%. The standard deviation 
of average task accuracy is 4\%.
