\subsection{Experiment Methodology}
\label{sec:methodology}
The experiment methodology follows Sudre et al.~\cite{Sudre2012} using the {\bf 2 vs 2 test}. We train a series of machine learning ridge regression models using the EEG data to generate the input features and individual indexes of {\bf word vectors} matching our word set as the models' predictions.

Specifically, we use the {\bf Skip-Gram} word vector set from Mikolov et al.~\cite{Mikolov2013}. Skip-Gram word vectors are generated by a neural network with a single hidden layer, trained to perform a word collocation task: the network receives a single word as input and predicts the probable collocated words for that input word. Pairs of words are generated from the Google News text corpus. After training, the weights of the model can approximate the probability of collocated words. Each word has associated weights, which create 300-dimensional vectors to use as training data in our experiment.

 Skip-Gram word vectors are a reasonable proxy for word semantics. Hollis et al. showed that Skip-Gram could predict human judgments for semantic tasks (e.g. sentiment ratings)~\cite{hollis2017extrapolating}. Hill et al. additionally concluded that Skip-Gram performs well on their SlimLex-999 evaluation, a high quality word similarity benchmark for computational models of word meaning~\cite{hill2016simlex}. Further, Murphy et al. showed that computational models can perform similarly to human benchmarks in the specific context of neurolinguistic decoding tasks~\cite{Murphy2012}, and subsequent work showed specifically that Skip-Gram could be used to identify the semantics of many word types in fMRI, EEG, and MEG~\cite{xu2016brainbench}. The semantic properties of these word vectors make them a useful tool for performing semantic analysis on brain data.
   
After the data preprocessing steps mentioned in Section \ref{sec:preprocessing}, every participant-symbol pair is represented by a tensor $D \in \mathbb{R}^{(r \times n_e \times l)}$, where $r$ can be between $0 \ldots n_t$, $n_t$ is the maximum number of possible trials seen for a given symbol, $n_e$ is the total number of electrodes, and $l$ is the number of time steps. Due to the randomness of the paradigm, $r$ varies across $D$s. Each trial is a matrix in $D$ with dimension $n_e \times l$. Further, we use $n_p$ to denote the number of participants and $n_s$ to denote the number of symbols. 

Depending on the type of analysis being performed, we select some trials from the set of all $D$. The selection process may choose all $D$ for certain participants or choose certain trials from each $D$ (see Section \ref{sec:results} and Section \ref{sec:discussion} for more details). We average across all participants and trials to create a tensor of dimension $n_s \times n_e \times l$, denoted as $D_\text{selected}$.  

This selection and averaging process is shown in Figure~\ref{fig:selection}.

\begin{figure}[t]
 \centerline{
   \includegraphics[width=1.5\linewidth]{figures/selection}
 }
 \caption{The trial selection pipeline. Our initial data contains participant-word pairs $(s, w)$ for $n_p$ participants and $n_s$ words that each contain between 0 and $n_t$ trials. The trials are of length $l$ and are recorded with $n_e$ electrodes. We select some subsection of these trials, and then average the data across participants to generate $(s, w)_{\text{selected}}$ which contains the averaged trials for each word.}
 \label{fig:selection}
\end{figure}

Before we train regression models, $D_{\text{selected}}$ is reshaped to produce a matrix with dimensions $X \in \mathbb{R}^{n_s \times (n_e * l)}$.  With a sampling rate of 250Hz for a 700ms window with 61 data sensors there will be $61*175 = 10675$ numerical features. We train $v$ independent regression models, such that we have one model to predict each dimension of the Skip-Gram word vector set. We use a linear least squares loss function and l2-norm regularization (ridge regression):

\begin{equation}
  \underset{w_i}{min\,} {|| X w_i - y_i||_2^2 + \alpha ||w_i||_2^2}
  \label{eq:ridge}
\end{equation}

\noindent where regression model $i$ is trained to predict the $i$th dimension of the word vectors (vector $y_i$) using weights $w_i$. $\alpha$ is a hyperparameter that controls the level of regularization. We use a standard $\alpha = 0.1$, although several values were tried empirically and found the only minor variation in performance. Using a trained regression model we can predict a single element of a word vector for a given input via $\hat{y}_i = x \cdot w_i$.

The weights of the individual models can be concatenated such that $W = [ w_1, w_2, ... w_v ]$. Collectively, $W$ is a single model that produces a predicted word vector using $\hat{y} = xW$. An example evaluation of the model on a single input vector $x$ from $X$ is seen in Figure ~\ref{fig:features}.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{figures/features}
  \caption{An evaluation of the trained model that predicts a word vector from EEG data. The set of regression models can be viewed collectively as a single model that takes a single averaged EEG trial $x$ as input and predicts a word vector $\hat{y}$ as output. $W$ is the learned weights from the regression models. The number of EEG features is $n$, which varies depending on the experiment, and $v$ is the length of the word vectors (for our experiments, $v=300$).}
  \label{fig:features}
\end{figure}

The set of ridge regression models are then evaluated in a ``leave two out'' fashion. That is, we hold out pairs of symbols $(y_i, y_j)$, and train ridge regression models to predict the vectors of the associated words using the EEG data from the remaining $n_s-2$ symbols.  The trained model is used to predict the two target word vectors $\hat{y}_i$ and $\hat{y}_j$ from the held out EEG data. The true word vectors ($y_i$, $y_j$) are then compared to the predicted word vectors ($\hat{y}_i$, $\hat{y}_j$) using a vector distance metric $d$ (in our case the cosine distance). The prediction is considered successful if the sum of the distances between the correctly matched true and predicted word vectors is smaller than the distance of the mismatched vectors as in: 

\begin{equation}
  d(y_i, \hat{y}_i) + d(y_j, \hat{y}_j) < d(y_i, \hat{y}_j) + d(y_j, \hat{y}_i)
  \label{eq:2vs2}
\end{equation}

\noindent We run this test for all possible ${\binom{n_s}{2}}$ pairs of words. Figure \ref{fig:2vs2} illustrates the \tvt test, where the solid lines are the distances between the correctly matched vectors (left hand of Equation \ref{eq:2vs2}) and the dashed lines are the distances between the incorrectly matched vectors (right hand of Equation \ref{eq:2vs2}). The \tvt test can detect if the EEG data is correlated with the word vectors. If the EEG data is not correlated to the word vectors, the 2 vs 2 accuracy (the percentage of the ${\binom{n_s}{2}}$ \tvt tests correct) will be  near the chance value of 50\%.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/2vs2}
  \caption{The \tvt, which simplifies word vector prediction to a binary decision task.  
 When the sum of the distances between the correctly aligned ground truth vectors and predicted vectors (solid lines) is smaller than the sum of the distances of the incorrectly aligned ground truth vectors and predicted vectors (dashed lines), the \tvt test is said to have passed.}
  \label{fig:2vs2}
\end{figure}
